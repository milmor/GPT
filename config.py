config = {'batch_size': 16,
          'buffer_size': 20000,
          'shuffle_seed': 32,
          'vocab_file': 'wiki_en_vocab',
          'min_seq_len': 32,
          'ckpt_interval': 200,
          'val_steps': 100,
          # hparams
          'vocab_size': 30000,
          'seq_len': 256,
          'learning_rate': 0.001,
          'beta_1': 0.9,
          'beta_2': 0.95,
          'decay_lr': False,
          'decay_steps': 2000,
          'emb_dim': 256,
          'heads': 8,
          'mlp_dim': 512,
          'depth': 10,
          'rate':  0.1,
          'initializer': 'glorot_uniform',
          'embedding_initializer': 'glorot_uniform', 
          'eps': 1e-6,
          'mlp_activation': 'gelu'}
