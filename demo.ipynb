{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2033ff5f-b1fc-4333-a477-6817b568872f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Disable tensorflow debugging logs\n",
    "import tensorflow as tf\n",
    "import keras_nlp\n",
    "import tensorflow_text as tf_text\n",
    "from model import GPT\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e57b61-8d1d-4ef1-b05b-d96438df0251",
   "metadata": {},
   "source": [
    "- Download weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63d52ba6-1bb6-4ba6-b21c-19f44d38b1c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ckpt_dir = 'openwt_512_d_512/best-ckpt'\n",
    "loader = Loader()\n",
    "loader.download(ckpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0c1d88e-045b-4e4c-bd0e-ff218e1fd44e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 16,\n",
       " 'buffer_size': 40000,\n",
       " 'shuffle_seed': 32,\n",
       " 'vocab_file': 'wiki_en_vocab',\n",
       " 'min_seq_len': False,\n",
       " 'ckpt_interval': 2000,\n",
       " 'val_steps': 1000,\n",
       " 'train_size': 95,\n",
       " 'vocab_size': 50257,\n",
       " 'seq_len': 512,\n",
       " 'learning_rate': 0.001,\n",
       " 'beta_1': 0.9,\n",
       " 'beta_2': 0.95,\n",
       " 'decay_lr': False,\n",
       " 'decay_steps': 400000,\n",
       " 'alpha': 0.1,\n",
       " 'emb_dim': 512,\n",
       " 'heads': 8,\n",
       " 'mlp_dim': 512,\n",
       " 'depth': 10,\n",
       " 'dropout': 0.0,\n",
       " 'initializer': 'glorot_uniform',\n",
       " 'embedding_initializer': 'glorot_uniform',\n",
       " 'eps': 1e-06,\n",
       " 'mlp_activation': 'gelu'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = loader.config\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7900cc4-774a-46d2-8561-95471eac4092",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = keras_nlp.models.GPT2Tokenizer.from_preset(\"gpt2_base_en\", \n",
    "                                                       sequence_length=config['seq_len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c02fb3f3-d5a4-42b1-be8e-7cef0dda2701",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = GPT(vocab_size=config['vocab_size'], \n",
    "            seq_len=config['seq_len'], emb_dim=config['emb_dim'],\n",
    "            heads=config['heads'], mlp_dim=config['mlp_dim'],\n",
    "            depth=config['depth'], rate=config['dropout'], \n",
    "            initializer=config['initializer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfee4545-c05d-407d-aa82-8fbbbb6a2302",
   "metadata": {},
   "source": [
    "- Initialize the model with a tokenized input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e254b330-34c0-4f26-87ba-d38e0d9054ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = 'The silver wolf is'\n",
    "t_context = tokenizer(tf_text.normalize_utf8(context, 'NFKD'))[tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a77377e-e1b5-4615-8836-6c47f4aa4c27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 512, 50257), dtype=float32, numpy=\n",
       "array([[[ 0.26018098, -0.099659  , -0.05211959, ..., -0.08389892,\n",
       "         -0.2226785 , -0.01996342],\n",
       "        [ 0.24848461, -0.10606524, -0.1408198 , ...,  0.02978064,\n",
       "         -0.24563235,  0.11638285],\n",
       "        [ 0.22778201, -0.11750411, -0.11632746, ..., -0.00105385,\n",
       "         -0.25143325,  0.2077703 ],\n",
       "        ...,\n",
       "        [ 0.2554393 , -0.11542156, -0.13028958, ..., -0.05494361,\n",
       "         -0.25776154,  0.16087352],\n",
       "        [ 0.24464783, -0.1165686 , -0.10335917, ..., -0.02977747,\n",
       "         -0.2302949 ,  0.17602484],\n",
       "        [ 0.29687753, -0.11166702, -0.12161556, ..., -0.04026931,\n",
       "         -0.32042617,  0.17742355]]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(t_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e05c83d8-e1f1-4c8c-b57e-bd280de7a2d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"gpt\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " token_embedding (TokenEmbed  multiple                 25993728  \n",
      " ding)                                                           \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         multiple                  0         \n",
      "                                                                 \n",
      " transformer_block (Transfor  multiple                 1577984   \n",
      " merBlock)                                                       \n",
      "                                                                 \n",
      " transformer_block_1 (Transf  multiple                 1577984   \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " transformer_block_2 (Transf  multiple                 1577984   \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " transformer_block_3 (Transf  multiple                 1577984   \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " transformer_block_4 (Transf  multiple                 1577984   \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " transformer_block_5 (Transf  multiple                 1577984   \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " transformer_block_6 (Transf  multiple                 1577984   \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " transformer_block_7 (Transf  multiple                 1577984   \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " transformer_block_8 (Transf  multiple                 1577984   \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " transformer_block_9 (Transf  multiple                 1577984   \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " layer_normalization_20 (Lay  multiple                 1024      \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " dense_60 (Dense)            multiple                  25781841  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67,556,433\n",
      "Trainable params: 67,556,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0f2388-a41b-4d5e-8dc1-9e946d813b5e",
   "metadata": {},
   "source": [
    "- Restore weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8c435cd-bf54-46f7-be67-1c573a4558fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint restored from openwt_512_d_512/best-ckpt/ckpt-1760000 at step 1760000\n"
     ]
    }
   ],
   "source": [
    "model.restore(ckpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca72c164-43b4-436c-81ab-8650f72ec664",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The silver wolf is actually going around â€” about 25 years earlier this day this March, as it passed around that morning and it finally got past 11 September for the first straight fall\n",
      " violations have led thousands of people back onto the road like a giant black wolf before moving onto the road last December where their car was being driven about 18 miles distant past 6,000 miles, a new kind (and not everyone on Facebook). Today as I drive south down a road I want myself the sound to be heard but like every second day on purpose here (and when an old man will be out Sunday I need just someone on and up here like many\n"
     ]
    }
   ],
   "source": [
    "text = sample(model, 'The silver wolf is', max_len=128, k=40)\n",
    "print(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
