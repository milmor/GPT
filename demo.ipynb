{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d31935cc-6b57-4d4d-b618-ee949c748437",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The MIT License (MIT) Copyright (c) 2022 milmor\n",
    "#\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy of \n",
    "# this software and associated documentation files (the \"Software\"), to deal in the Software without \n",
    "# restriction, including without limitation the rights to use, copy, modify, merge, publish, \n",
    "# distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the \n",
    "# Software is furnished to do so, subject to the following conditions:\n",
    "#\n",
    "# The above copyright notice and this permission notice shall be included in all copies or \n",
    "# substantial portions of the Software.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, \n",
    "# INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND \n",
    "# NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES \n",
    "# OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN \n",
    "# CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2033ff5f-b1fc-4333-a477-6817b568872f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Disable tensorflow debugging logs\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import keras_nlp\n",
    "import tensorflow_text as tf_text\n",
    "from huggingface_hub import hf_hub_download\n",
    "from model import GPT\n",
    "from utils import sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e57b61-8d1d-4ef1-b05b-d96438df0251",
   "metadata": {},
   "source": [
    "- Download weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63d52ba6-1bb6-4ba6-b21c-19f44d38b1c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ckpt_dir = 'openwt_512/best-ckpt'\n",
    "\n",
    "hf_hub_download(repo_id=\"milmor/gpt-mini\", \n",
    "                filename=f\"{ckpt_dir}/ckpt-934000.data-00000-of-00001\",\n",
    "                local_dir='./')\n",
    "\n",
    "hf_hub_download(repo_id=\"milmor/gpt-mini\", \n",
    "                filename=f\"{ckpt_dir}/ckpt-934000.index\",\n",
    "                local_dir='./')\n",
    "\n",
    "hf_hub_download(repo_id=\"milmor/gpt-mini\", \n",
    "                filename=f\"{ckpt_dir}/checkpoint\",\n",
    "                local_dir='./')\n",
    "\n",
    "config_file = hf_hub_download(repo_id=\"milmor/mini-gpt\", \n",
    "                filename=\"openwt_512/openwt_512_config.json\",\n",
    "                local_dir='./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78c3c9cf-64d8-4f7f-9126-168b93c5c8f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(config_file) as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7900cc4-774a-46d2-8561-95471eac4092",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = keras_nlp.tokenizers.WordPieceTokenizer(\n",
    "    vocabulary=config['vocab_file'],\n",
    "    sequence_length=config['seq_len'] + 1,\n",
    "    lowercase=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c02fb3f3-d5a4-42b1-be8e-7cef0dda2701",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = GPT(vocab_size=config['vocab_size'], \n",
    "            maxlen=config['seq_len'], emb_dim=config['emb_dim'],\n",
    "            heads=config['heads'], mlp_dim=config['mlp_dim'],\n",
    "            depth=config['depth'], rate=config['dropout'], \n",
    "            initializer=config['initializer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfee4545-c05d-407d-aa82-8fbbbb6a2302",
   "metadata": {},
   "source": [
    "- Initialize the model with a tokenized input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e254b330-34c0-4f26-87ba-d38e0d9054ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = 'I love the wolf'\n",
    "t_context = tokenizer(tf_text.normalize_utf8(context, 'NFKD'))[tf.newaxis, :config['seq_len']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a77377e-e1b5-4615-8836-6c47f4aa4c27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 512, 30000), dtype=float32, numpy=\n",
       "array([[[-0.1073962 ,  0.12308779, -0.11740228, ...,  0.13619076,\n",
       "          0.06594768,  0.0167977 ],\n",
       "        [-0.09143426,  0.06127262, -0.14263633, ...,  0.07504728,\n",
       "          0.05748158,  0.0266253 ],\n",
       "        [-0.10384098,  0.10336254, -0.14206518, ...,  0.13705155,\n",
       "          0.05703758,  0.0183858 ],\n",
       "        ...,\n",
       "        [-0.10039534,  0.08161308, -0.13666598, ...,  0.10743341,\n",
       "          0.05216627,  0.07849834],\n",
       "        [-0.1001814 ,  0.11536416, -0.0875769 , ...,  0.14495653,\n",
       "          0.02732199,  0.0766139 ],\n",
       "        [-0.06502417,  0.08763284, -0.10016494, ...,  0.13450669,\n",
       "          0.07237849,  0.04055046]]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(t_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e05c83d8-e1f1-4c8c-b57e-bd280de7a2d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"gpt\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " token_embedding (TokenEmbed  multiple                 7811072   \n",
      " ding)                                                           \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         multiple                  0         \n",
      "                                                                 \n",
      " transformer_block (Transfor  multiple                 527104    \n",
      " merBlock)                                                       \n",
      "                                                                 \n",
      " transformer_block_1 (Transf  multiple                 527104    \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " transformer_block_2 (Transf  multiple                 527104    \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " transformer_block_3 (Transf  multiple                 527104    \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " transformer_block_4 (Transf  multiple                 527104    \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " transformer_block_5 (Transf  multiple                 527104    \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " transformer_block_6 (Transf  multiple                 527104    \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " transformer_block_7 (Transf  multiple                 527104    \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " transformer_block_8 (Transf  multiple                 527104    \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " transformer_block_9 (Transf  multiple                 527104    \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " transformer_block_10 (Trans  multiple                 527104    \n",
      " formerBlock)                                                    \n",
      "                                                                 \n",
      " transformer_block_11 (Trans  multiple                 527104    \n",
      " formerBlock)                                                    \n",
      "                                                                 \n",
      " layer_normalization_24 (Lay  multiple                 512       \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " dense_72 (Dense)            multiple                  7710000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,846,832\n",
      "Trainable params: 21,846,832\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0f2388-a41b-4d5e-8dc1-9e946d813b5e",
   "metadata": {},
   "source": [
    "- Restore weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8c435cd-bf54-46f7-be67-1c573a4558fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint restored from openwt_512/best-ckpt/ckpt-934000 at step 934000\n"
     ]
    }
   ],
   "source": [
    "ckpt = tf.train.Checkpoint(model=model, step=tf.Variable(0))\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, directory=ckpt_dir, \n",
    "                                          max_to_keep=1)\n",
    "ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "print(f'Checkpoint restored from {ckpt_manager.latest_checkpoint} at step {int(ckpt.step)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9b801c3-2a1f-4c72-a058-1e3335c4a0f4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I love the wolf - mongered , but the only problem we find most likely about us . A couple hundred feet away at our last hour of work , a half dozen people are on your back with an eye , and a small amount will take off at least the next one . I was able to keep a small , but still - tall bougin in the middle , in my hand , in an attempt for the best to be a bit overdrching for his work to come back . It was not a surprise I found it on his phone as a small , buffet . And he got to the front seat of one man to the front door on my head to stumble on his head . A baunt with a stomping paper is probably the biggest pain of his illness that has led us to an illnesses in a single cell which means no need for a doctor , so there ’ ve only gotten a couple days in my life to go to a good care unit at his home , and the one on a bed where his son died was in his late life and that ’ d been his best friend for over a long time ! But the bro ! The bro is one and that ’ chuckles in your face . This is a very hard situation , and a great time . A little more to his surprise : The guy who ’ em up the stomps has just begun . I ’ m so excited about how many things the guys he had been through in an early morning day , a little while back at home in his house – but that doesn t make a lot easier and I dona ’ d think that I am too . But this isne to say it was in the end he had his phone , as a booch for about three and a then , the baunched stairmaltho – but it didn ’ t happen . A little , so we don ’ m not in the right direction – I know that it will have to take some time to take the picture of himself , though – but I can just wait the other way around ! And , it ’ re so long that a little bro . So I got into his room in which I ’ t really feel like the person who had my hand . The guys he was in had their eyes in their hand and said that he did , that was just too hard but that we did . So he went in the kitchen – that was one . So he said , ‘ you have an easy and powerful job'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = sample(model, context, config['seq_len'], config['vocab_file'], k=10)\n",
    "text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
