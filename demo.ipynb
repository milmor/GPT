{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2033ff5f-b1fc-4333-a477-6817b568872f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Disable tensorflow debugging logs\n",
    "import tensorflow as tf\n",
    "import keras_nlp\n",
    "import tensorflow_text as tf_text\n",
    "from model import GPT\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e57b61-8d1d-4ef1-b05b-d96438df0251",
   "metadata": {},
   "source": [
    "- Download weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63d52ba6-1bb6-4ba6-b21c-19f44d38b1c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ckpt_dir = 'openwt_512_d_512/best-ckpt'\n",
    "loader = Loader()\n",
    "loader.download(ckpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0c1d88e-045b-4e4c-bd0e-ff218e1fd44e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 16,\n",
       " 'buffer_size': 40000,\n",
       " 'shuffle_seed': 32,\n",
       " 'vocab_file': 'wiki_en_vocab',\n",
       " 'min_seq_len': False,\n",
       " 'ckpt_interval': 2000,\n",
       " 'val_steps': 1000,\n",
       " 'train_size': 95,\n",
       " 'vocab_size': 50257,\n",
       " 'seq_len': 512,\n",
       " 'learning_rate': 0.001,\n",
       " 'beta_1': 0.9,\n",
       " 'beta_2': 0.95,\n",
       " 'decay_lr': False,\n",
       " 'decay_steps': 400000,\n",
       " 'alpha': 0.1,\n",
       " 'emb_dim': 512,\n",
       " 'heads': 8,\n",
       " 'mlp_dim': 512,\n",
       " 'depth': 10,\n",
       " 'dropout': 0.0,\n",
       " 'initializer': 'glorot_uniform',\n",
       " 'embedding_initializer': 'glorot_uniform',\n",
       " 'eps': 1e-06,\n",
       " 'mlp_activation': 'gelu'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = loader.config\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7900cc4-774a-46d2-8561-95471eac4092",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = keras_nlp.models.GPT2Tokenizer.from_preset(\"gpt2_base_en\", \n",
    "                                                       sequence_length=config['seq_len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c02fb3f3-d5a4-42b1-be8e-7cef0dda2701",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = GPT(vocab_size=config['vocab_size'], \n",
    "            seq_len=config['seq_len'], emb_dim=config['emb_dim'],\n",
    "            heads=config['heads'], mlp_dim=config['mlp_dim'],\n",
    "            depth=config['depth'], rate=config['dropout'], \n",
    "            initializer=config['initializer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfee4545-c05d-407d-aa82-8fbbbb6a2302",
   "metadata": {},
   "source": [
    "- Initialize the model with a tokenized input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e254b330-34c0-4f26-87ba-d38e0d9054ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = 'The silver wolf is'\n",
    "t_context = tokenizer(tf_text.normalize_utf8(context, 'NFKD'))[tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a77377e-e1b5-4615-8836-6c47f4aa4c27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 512, 50257), dtype=float32, numpy=\n",
       "array([[[ 0.01578266, -0.01593508,  0.08134665, ...,  0.16397418,\n",
       "         -0.07980248,  0.05148029],\n",
       "        [-0.0891059 , -0.00203854,  0.07782   , ...,  0.15241538,\n",
       "         -0.00872427,  0.00942059],\n",
       "        [-0.09127087,  0.10816865,  0.07026106, ...,  0.07882239,\n",
       "         -0.0064379 ,  0.02395548],\n",
       "        ...,\n",
       "        [-0.08796776,  0.08953027,  0.12804441, ...,  0.0775993 ,\n",
       "          0.06395972, -0.0393813 ],\n",
       "        [-0.16385601,  0.02793138,  0.10487607, ...,  0.04041716,\n",
       "         -0.00516192,  0.07077672],\n",
       "        [-0.10391336,  0.06668523,  0.07727648, ...,  0.08824315,\n",
       "         -0.00982571,  0.02639535]]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(t_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e05c83d8-e1f1-4c8c-b57e-bd280de7a2d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"gpt\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " token_embedding (TokenEmbed  multiple                 25993728  \n",
      " ding)                                                           \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         multiple                  0         \n",
      "                                                                 \n",
      " transformer_block (Transfor  multiple                 1577984   \n",
      " merBlock)                                                       \n",
      "                                                                 \n",
      " transformer_block_1 (Transf  multiple                 1577984   \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " transformer_block_2 (Transf  multiple                 1577984   \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " transformer_block_3 (Transf  multiple                 1577984   \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " transformer_block_4 (Transf  multiple                 1577984   \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " transformer_block_5 (Transf  multiple                 1577984   \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " transformer_block_6 (Transf  multiple                 1577984   \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " transformer_block_7 (Transf  multiple                 1577984   \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " transformer_block_8 (Transf  multiple                 1577984   \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " transformer_block_9 (Transf  multiple                 1577984   \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " layer_normalization_20 (Lay  multiple                 1024      \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " dense_60 (Dense)            multiple                  25781841  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67,556,433\n",
      "Trainable params: 67,556,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0f2388-a41b-4d5e-8dc1-9e946d813b5e",
   "metadata": {},
   "source": [
    "- Restore weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8c435cd-bf54-46f7-be67-1c573a4558fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint restored from openwt_512_d_512/best-ckpt/ckpt-1760000 at step 1760000\n"
     ]
    }
   ],
   "source": [
    "model.restore(ckpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca72c164-43b4-436c-81ab-8650f72ec664",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The black wolf is important for the planet in our present day and we are in this situation where the black wolf can be found at the center\n",
      " The black wolf has no black wolf, but is one big black wolf to be found there because its hunting is in an entirely different form â€” not just because there are many black wolves in this picture? As you will, there is the opportunity to see black wolves at some very small location in the North America with a black wolf and they are all a part or part, in part one or more people in our modern society are not in any form. We need you in the wild for all to\n"
     ]
    }
   ],
   "source": [
    "text = sample(model, 'The black wolf is important for the planet', max_len=128, k=10)\n",
    "print(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
