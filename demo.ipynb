{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2033ff5f-b1fc-4333-a477-6817b568872f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Disable tensorflow debugging logs\n",
    "import tensorflow as tf\n",
    "import keras_nlp\n",
    "import tensorflow_text as tf_text\n",
    "from model import GPT\n",
    "from utils import *\n",
    "from config import config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e57b61-8d1d-4ef1-b05b-d96438df0251",
   "metadata": {},
   "source": [
    "- Download weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63d52ba6-1bb6-4ba6-b21c-19f44d38b1c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = 'openwt_512_d_512' \n",
    "ckpt_dir = f'{model_name}/best-ckpt' \n",
    "loader = Loader()\n",
    "loader.download(ckpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0c1d88e-045b-4e4c-bd0e-ff218e1fd44e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config openwt_512_d_512/openwt_512_d_512_config.json loaded\n",
      "{'batch_size': 16, 'buffer_size': 40000, 'shuffle_seed': 32, 'vocab_file': 'wiki_en_vocab', 'min_seq_len': False, 'ckpt_interval': 2000, 'val_steps': 1000, 'train_size': 95, 'vocab_size': 50257, 'seq_len': 512, 'learning_rate': 0.001, 'beta_1': 0.9, 'beta_2': 0.95, 'decay_lr': False, 'decay_steps': 400000, 'alpha': 0.1, 'emb_dim': 512, 'heads': 8, 'mlp_dim': 512, 'depth': 10, 'dropout': 0.0, 'initializer': 'glorot_uniform', 'embedding_initializer': 'glorot_uniform', 'eps': 1e-06, 'mlp_activation': 'gelu'}\n"
     ]
    }
   ],
   "source": [
    "conf = Config(config, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c02fb3f3-d5a4-42b1-be8e-7cef0dda2701",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = GPT(vocab_size=conf.vocab_size, \n",
    "            seq_len=conf.seq_len, emb_dim=conf.emb_dim,\n",
    "            heads=conf.heads, mlp_dim=conf.mlp_dim,\n",
    "            depth=conf.depth, rate=conf.dropout, \n",
    "            initializer=conf.initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e05c83d8-e1f1-4c8c-b57e-bd280de7a2d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"gpt\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " token_embedding (TokenEmbe  multiple                  25993728  \n",
      " dding)                                                          \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         multiple                  0         \n",
      "                                                                 \n",
      " transformer_block (Transfo  multiple                  1577984   \n",
      " rmerBlock)                                                      \n",
      "                                                                 \n",
      " transformer_block_1 (Trans  multiple                  1577984   \n",
      " formerBlock)                                                    \n",
      "                                                                 \n",
      " transformer_block_2 (Trans  multiple                  1577984   \n",
      " formerBlock)                                                    \n",
      "                                                                 \n",
      " transformer_block_3 (Trans  multiple                  1577984   \n",
      " formerBlock)                                                    \n",
      "                                                                 \n",
      " transformer_block_4 (Trans  multiple                  1577984   \n",
      " formerBlock)                                                    \n",
      "                                                                 \n",
      " transformer_block_5 (Trans  multiple                  1577984   \n",
      " formerBlock)                                                    \n",
      "                                                                 \n",
      " transformer_block_6 (Trans  multiple                  1577984   \n",
      " formerBlock)                                                    \n",
      "                                                                 \n",
      " transformer_block_7 (Trans  multiple                  1577984   \n",
      " formerBlock)                                                    \n",
      "                                                                 \n",
      " transformer_block_8 (Trans  multiple                  1577984   \n",
      " formerBlock)                                                    \n",
      "                                                                 \n",
      " transformer_block_9 (Trans  multiple                  1577984   \n",
      " formerBlock)                                                    \n",
      "                                                                 \n",
      " layer_normalization_20 (La  multiple                  1024      \n",
      " yerNormalization)                                               \n",
      "                                                                 \n",
      " dense_60 (Dense)            multiple                  25781841  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67556433 (257.71 MB)\n",
      "Trainable params: 67556433 (257.71 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0f2388-a41b-4d5e-8dc1-9e946d813b5e",
   "metadata": {},
   "source": [
    "- Restore weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8c435cd-bf54-46f7-be67-1c573a4558fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint restored from openwt_512_d_512/best-ckpt/ckpt-1760000 at step 1760000\n"
     ]
    }
   ],
   "source": [
    "model.restore(ckpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37b63b85-eeb8-4d44-a578-dcba2b8d6461",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = keras_nlp.models.GPT2Tokenizer.from_preset(\"gpt2_base_en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83cb46a9-e4cc-49e2-b1c4-fa303d0616d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dark ring’s more than one-notch ring, ‘Rights to the Edge of the Universe,’ is still in the spotlight\n"
     ]
    }
   ],
   "source": [
    "text = sample(model, tokenizer, 'The dark ring', max_len=32, k=50, seed=123, temperature=1.0)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a336714-65e8-41e2-9283-4c142330d474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dark ring’s more than one-notch ring, ‘Rights of the End’, the idea of a unique, dynamic ring, with a thin ring that includes a few different types of gear, and a couple of different types of gear over the course of a single year. While many models of the ring use the same high quality and high-quality format, there are a lot of options for those of us who want to add some extra value to the ring.\n",
      "\n",
      "As you can see in this article:\n",
      "\n",
      "It’s been done since April 2012 (with the latest results of the\n"
     ]
    }
   ],
   "source": [
    "text = sample(model, tokenizer, 'The dark ring', max_len=128, k=50, seed=123, temperature=0.9)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f078a16f-e4b1-4c6d-8643-885b2b76159e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dark ring of the United States’s most famous war machine, the Black Sea, is the first of its kind in the world. The White Sea is home to the world’s most famous war machine, the Black Sea.\n",
      "\n",
      "The Black Sea is a small town in the northeast corner of the city of San Diego. It is also the largest city in the world.\n",
      "\n",
      "The Black Sea is a city on the border between the United States and Russia. It is a town in the southernmost part of the U.S., and it is the largest city in the world.\n",
      "\n",
      "The Black Sea is\n"
     ]
    }
   ],
   "source": [
    "text = sample(model, tokenizer, 'The dark ring', max_len=128, k=50, seed=123, temperature=0.5)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c2713aa-7236-4428-a79c-48080853bc55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dark ring’s more than one-notch ring, ‘Rights of the End’, the idea of a unique, dynamic ring, with a thin ring that includes a few different types of gear, and a couple of different types of gear over the course of a single year. While many models of the ring use the same high quality and high-quality format, there are a lot of options for those of us who want to add some extra value to the ring.\n",
      "\n",
      "As you can see in this article:\n",
      "\n",
      "It’s been done since April 2012 (with the latest results of the research):\n",
      "\n",
      "The ring is a small ring. It’s a small ring but a single year, but it’s not perfect. It’s more and more distinct than other ring.\n",
      "\n",
      "The ring is about the size and scale of a ring and is all about the width of a ring. A ton of different and more important details come from the ring, as well as the depth of the ring, which is the type of ring. This ring is also about the size of a ring.\n",
      "\n",
      "The real ring includes the same number of different design different types, but there are a lot of different types of gear. For example, the ring contains a few different types of gear, and some of them are made. If this ring was used for the number of tools, it would easily be a bit smaller and more expensive than the ring, but the ring is good for some types of gear and not just the ring.\n",
      "\n",
      "The ring as a ring is a small ring designed to be a single size and will always be designed as many a smaller ring. People with different designs would be able to make the ring, but most of the major ones are smaller. In this article we’ll discuss the two types of ring, as well as the ‘Hijack’ and ‘Laving Up’, when it really is ready to be a good ring, the ring could be used to make your ring more functional and useful.\n",
      "\n",
      "(For one things to tell)\n",
      "\n",
      "The ring is a small ring called a ring, which is the sort of ring that is made with a ring.\n",
      "\n",
      "The ring can be used to make the ring more functional, although a little of your basic ring needs help.\n",
      "\n",
      "But unless you’re like many others you need to make a ring that is different than the ring, and\n"
     ]
    }
   ],
   "source": [
    "text = sample(model, tokenizer, 'The dark ring', max_len=512, k=50, seed=123, temperature=0.9)\n",
    "print(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
