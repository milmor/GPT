{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2033ff5f-b1fc-4333-a477-6817b568872f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Disable tensorflow debugging logs\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import keras_nlp\n",
    "import tensorflow_text as tf_text\n",
    "from huggingface_hub import hf_hub_download\n",
    "from model import GPT\n",
    "from utils import sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e57b61-8d1d-4ef1-b05b-d96438df0251",
   "metadata": {},
   "source": [
    "- Download weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63d52ba6-1bb6-4ba6-b21c-19f44d38b1c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ckpt_dir = 'openwt_512/best-ckpt'\n",
    "\n",
    "hf_hub_download(repo_id=\"milmor/gpt-mini\", \n",
    "                filename=f\"{ckpt_dir}/ckpt-934000.data-00000-of-00001\",\n",
    "                local_dir='./')\n",
    "\n",
    "hf_hub_download(repo_id=\"milmor/gpt-mini\", \n",
    "                filename=f\"{ckpt_dir}/ckpt-934000.index\",\n",
    "                local_dir='./')\n",
    "\n",
    "hf_hub_download(repo_id=\"milmor/gpt-mini\", \n",
    "                filename=f\"{ckpt_dir}/checkpoint\",\n",
    "                local_dir='./')\n",
    "\n",
    "config_file = hf_hub_download(repo_id=\"milmor/mini-gpt\", \n",
    "                filename=\"openwt_512/openwt_512_config.json\",\n",
    "                local_dir='./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78c3c9cf-64d8-4f7f-9126-168b93c5c8f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(config_file) as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7900cc4-774a-46d2-8561-95471eac4092",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = keras_nlp.tokenizers.WordPieceTokenizer(\n",
    "    vocabulary=config['vocab_file'],\n",
    "    sequence_length=config['seq_len'] + 1,\n",
    "    lowercase=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c02fb3f3-d5a4-42b1-be8e-7cef0dda2701",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = GPT(vocab_size=config['vocab_size'], \n",
    "            maxlen=config['seq_len'], emb_dim=config['emb_dim'],\n",
    "            heads=config['heads'], mlp_dim=config['mlp_dim'],\n",
    "            depth=config['depth'], rate=config['dropout'], \n",
    "            initializer=config['initializer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfee4545-c05d-407d-aa82-8fbbbb6a2302",
   "metadata": {},
   "source": [
    "- Initialize the model with a tokenized input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e254b330-34c0-4f26-87ba-d38e0d9054ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = 'The magic wolf'\n",
    "t_context = tokenizer(tf_text.normalize_utf8(context, 'NFKD'))[tf.newaxis, :config['seq_len']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a77377e-e1b5-4615-8836-6c47f4aa4c27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 512, 30000), dtype=float32, numpy=\n",
       "array([[[ 1.24882199e-01, -1.90662801e-01, -5.42290360e-02, ...,\n",
       "         -1.69452175e-01,  4.31207195e-02,  1.56254560e-01],\n",
       "        [-3.41758579e-02, -2.29694188e-01, -5.64303249e-02, ...,\n",
       "         -3.65731306e-02,  4.46557067e-03,  1.43037230e-01],\n",
       "        [-9.96448100e-03, -1.91211447e-01,  2.62345690e-02, ...,\n",
       "         -8.47366154e-02, -4.69740480e-05,  1.37593210e-01],\n",
       "        ...,\n",
       "        [-1.84914228e-02, -1.91389024e-01,  3.00798025e-02, ...,\n",
       "         -7.88995177e-02,  2.05447171e-02,  1.02667749e-01],\n",
       "        [ 7.88632222e-03, -2.08302900e-01,  3.57170664e-02, ...,\n",
       "         -8.79053846e-02,  3.98159064e-02,  8.13047886e-02],\n",
       "        [-1.53083075e-02, -1.83072627e-01,  4.67220768e-02, ...,\n",
       "         -2.98853554e-02,  1.43598095e-02,  1.04361206e-01]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(t_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e05c83d8-e1f1-4c8c-b57e-bd280de7a2d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"gpt\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " token_embedding (TokenEmbed  multiple                 7811072   \n",
      " ding)                                                           \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         multiple                  0         \n",
      "                                                                 \n",
      " transformer_block (Transfor  multiple                 527104    \n",
      " merBlock)                                                       \n",
      "                                                                 \n",
      " transformer_block_1 (Transf  multiple                 527104    \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " transformer_block_2 (Transf  multiple                 527104    \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " transformer_block_3 (Transf  multiple                 527104    \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " transformer_block_4 (Transf  multiple                 527104    \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " transformer_block_5 (Transf  multiple                 527104    \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " transformer_block_6 (Transf  multiple                 527104    \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " transformer_block_7 (Transf  multiple                 527104    \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " transformer_block_8 (Transf  multiple                 527104    \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " transformer_block_9 (Transf  multiple                 527104    \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " transformer_block_10 (Trans  multiple                 527104    \n",
      " formerBlock)                                                    \n",
      "                                                                 \n",
      " transformer_block_11 (Trans  multiple                 527104    \n",
      " formerBlock)                                                    \n",
      "                                                                 \n",
      " layer_normalization_24 (Lay  multiple                 512       \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " dense_72 (Dense)            multiple                  7710000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,846,832\n",
      "Trainable params: 21,846,832\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0f2388-a41b-4d5e-8dc1-9e946d813b5e",
   "metadata": {},
   "source": [
    "- Restore weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8c435cd-bf54-46f7-be67-1c573a4558fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint restored from openwt_512/best-ckpt/ckpt-934000 at step 934000\n"
     ]
    }
   ],
   "source": [
    "ckpt = tf.train.Checkpoint(model=model, step=tf.Variable(0))\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, directory=ckpt_dir, \n",
    "                                          max_to_keep=1)\n",
    "ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "print(f'Checkpoint restored from {ckpt_manager.latest_checkpoint} at step {int(ckpt.step)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9b801c3-2a1f-4c72-a058-1e3335c4a0f4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The magic wolf , the shiny , uninjecting , is an ex - soldier who was in an old , hard and britting shindy . His mother was on an outfield of an old train on the Brix - West train . When he learned he ’ was coming , he learned the secret information , but no one was aware how important , as it may have been and how it would impact a long distance run : It was a tale of an old girl and the girl who took over in her head , in one - off a new ship he has now left to travel in and back for three minutes : her husband and the sister she lives with in a home . The only one of our friends , one with the best son and father and a son is a small brother — but she was born with the girl . In a series called , “ A Girl When It Look Into “ : a . k . an intrylish , a , a little out to me , ” it might also appear like a little intridulity — as a result . This story had become something like The Last Star – A Little Out Boy And a few years before it , I started thinking about this and my mother went to school , so the only question was how it would hurt me as it would damage a boy or sister ’ s identity — and my mother died with the little boy ’ em and her father died with an infection in it : Why ? It was an amazing thing ; I know it happened in her , and this time we got it in her , they said . We did , however I thought we were all the badass at the time to start it all up on his face in my bed as she had not found out , then I saw my son , his mother and that was all my family was trying out in the family that it had done to be an ab . This is how you get a little in a room with this man who has had some serious problems as his life has changed , which was very , completely different — but this isn to the boy who is on our feet that he will not find any way his body might change to help me in a way he does well and he will never die with my father as a teenager or even for us to be a part of him as his son is , for sure ! He was in his best friends with his father ’ , and I am proud and happy to be in my house with the girl she has lived up all day , ” a little goes'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = sample(model, context, config['seq_len'], config['vocab_file'], k=10)\n",
    "text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
