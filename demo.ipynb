{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2033ff5f-b1fc-4333-a477-6817b568872f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Disable tensorflow debugging logs\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import keras_nlp\n",
    "import tensorflow_text as tf_text\n",
    "from huggingface_hub import hf_hub_download\n",
    "from model import GPT\n",
    "from utils import sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e57b61-8d1d-4ef1-b05b-d96438df0251",
   "metadata": {},
   "source": [
    "- Download weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63d52ba6-1bb6-4ba6-b21c-19f44d38b1c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ckpt_dir = 'openwt_512_d_512/best-ckpt'\n",
    "\n",
    "hf_hub_download(repo_id=\"milmor/gpt-mini\", \n",
    "                filename=f\"{ckpt_dir}/ckpt-616000.data-00000-of-00001\",\n",
    "                local_dir='./')\n",
    "\n",
    "hf_hub_download(repo_id=\"milmor/gpt-mini\", \n",
    "                filename=f\"{ckpt_dir}/ckpt-616000.index\",\n",
    "                local_dir='./')\n",
    "\n",
    "hf_hub_download(repo_id=\"milmor/gpt-mini\", \n",
    "                filename=f\"{ckpt_dir}/checkpoint\",\n",
    "                local_dir='./')\n",
    "\n",
    "config_file = hf_hub_download(repo_id=\"milmor/gpt-mini\", \n",
    "                filename=\"openwt_512_d_512/openwt_512_d_512_config.json\",\n",
    "                local_dir='./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0c1d88e-045b-4e4c-bd0e-ff218e1fd44e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./openwt_512_d_512/openwt_512_d_512_config.json'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acf330b8-c6b8-4fb8-a139-a4c2576ac5c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(config_file) as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7900cc4-774a-46d2-8561-95471eac4092",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = keras_nlp.models.GPT2Tokenizer.from_preset(\"gpt2_base_en\", \n",
    "                                                       sequence_length=config['seq_len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c02fb3f3-d5a4-42b1-be8e-7cef0dda2701",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = GPT(vocab_size=config['vocab_size'], \n",
    "            maxlen=config['seq_len'], emb_dim=config['emb_dim'],\n",
    "            heads=config['heads'], mlp_dim=config['mlp_dim'],\n",
    "            depth=config['depth'], rate=config['dropout'], \n",
    "            initializer=config['initializer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfee4545-c05d-407d-aa82-8fbbbb6a2302",
   "metadata": {},
   "source": [
    "- Initialize the model with a tokenized input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e254b330-34c0-4f26-87ba-d38e0d9054ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = 'The silver wolf is'\n",
    "t_context = tokenizer(tf_text.normalize_utf8(context, 'NFKD'))[tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a77377e-e1b5-4615-8836-6c47f4aa4c27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 512, 50257), dtype=float32, numpy=\n",
       "array([[[-0.04117207, -0.01061924,  0.14581442, ..., -0.13442373,\n",
       "         -0.14407264, -0.19951549],\n",
       "        [-0.09236404, -0.00886059,  0.1487286 , ..., -0.18754527,\n",
       "          0.09094065, -0.12930349],\n",
       "        [-0.14570114,  0.04800888,  0.21148913, ..., -0.23972818,\n",
       "         -0.0096932 , -0.19432347],\n",
       "        ...,\n",
       "        [-0.20269476, -0.09608932,  0.06118559, ..., -0.24732275,\n",
       "          0.06152881, -0.25288272],\n",
       "        [-0.10632226, -0.02713121,  0.10409077, ..., -0.16089398,\n",
       "         -0.02387796, -0.1616822 ],\n",
       "        [-0.14942929, -0.07109308,  0.13973953, ..., -0.22269347,\n",
       "         -0.00802256, -0.24788411]]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(t_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e05c83d8-e1f1-4c8c-b57e-bd280de7a2d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"gpt\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " token_embedding (TokenEmbed  multiple                 25993728  \n",
      " ding)                                                           \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         multiple                  0         \n",
      "                                                                 \n",
      " transformer_block (Transfor  multiple                 1577984   \n",
      " merBlock)                                                       \n",
      "                                                                 \n",
      " transformer_block_1 (Transf  multiple                 1577984   \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " transformer_block_2 (Transf  multiple                 1577984   \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " transformer_block_3 (Transf  multiple                 1577984   \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " transformer_block_4 (Transf  multiple                 1577984   \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " transformer_block_5 (Transf  multiple                 1577984   \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " transformer_block_6 (Transf  multiple                 1577984   \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " transformer_block_7 (Transf  multiple                 1577984   \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " transformer_block_8 (Transf  multiple                 1577984   \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " transformer_block_9 (Transf  multiple                 1577984   \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " layer_normalization_20 (Lay  multiple                 1024      \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " dense_60 (Dense)            multiple                  25781841  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67,556,433\n",
      "Trainable params: 67,556,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0f2388-a41b-4d5e-8dc1-9e946d813b5e",
   "metadata": {},
   "source": [
    "- Restore weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8c435cd-bf54-46f7-be67-1c573a4558fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint restored from openwt_512_d_512/best-ckpt/ckpt-616000 at step 616000\n"
     ]
    }
   ],
   "source": [
    "ckpt = tf.train.Checkpoint(model=model, step=tf.Variable(0))\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, directory=ckpt_dir, \n",
    "                                          max_to_keep=1)\n",
    "ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "print(f'Checkpoint restored from {ckpt_manager.latest_checkpoint} at step {int(ckpt.step)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca72c164-43b4-436c-81ab-8650f72ec664",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The silver wolf is \"the most important\" sign ever.\\n\\nThe wolf in front as in 2008 became synonymous when Jim Brown-Maggie sat quietly out through this room last Tuesday over her face during debate in Miami Park‘tear at it lunchfocused panel . And it never looked quite interesting after reading Browner in on other questions—and to what appeared more surprising. So this evening though she began talking from on Friday during Thursday\\'s questions with me in terms he knew not very good (and she got about how difficult they do her day because not much we call her after we reach the red wolf they\\'ll live together'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = sample(model, 'The silver wolf is', config['seq_len'], max_len=128, k=40)\n",
    "text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
