{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d31935cc-6b57-4d4d-b618-ee949c748437",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The MIT License (MIT) Copyright (c) 2022 milmor\n",
    "#\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy of \n",
    "# this software and associated documentation files (the \"Software\"), to deal in the Software without \n",
    "# restriction, including without limitation the rights to use, copy, modify, merge, publish, \n",
    "# distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the \n",
    "# Software is furnished to do so, subject to the following conditions:\n",
    "#\n",
    "# The above copyright notice and this permission notice shall be included in all copies or \n",
    "# substantial portions of the Software.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, \n",
    "# INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND \n",
    "# NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES \n",
    "# OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN \n",
    "# CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2033ff5f-b1fc-4333-a477-6817b568872f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Disable tensorflow debugging logs\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import keras_nlp\n",
    "import tensorflow_text as tf_text\n",
    "from huggingface_hub import hf_hub_download\n",
    "from model import GPT\n",
    "from utils import sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e57b61-8d1d-4ef1-b05b-d96438df0251",
   "metadata": {},
   "source": [
    "- Download weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63d52ba6-1bb6-4ba6-b21c-19f44d38b1c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ckpt_dir = 'openwt_512/best-ckpt'\n",
    "\n",
    "hf_hub_download(repo_id=\"milmor/gpt-mini\", \n",
    "                filename=f\"{ckpt_dir}/ckpt-934000.data-00000-of-00001\",\n",
    "                local_dir='./')\n",
    "\n",
    "hf_hub_download(repo_id=\"milmor/gpt-mini\", \n",
    "                filename=f\"{ckpt_dir}/ckpt-934000.index\",\n",
    "                local_dir='./')\n",
    "\n",
    "hf_hub_download(repo_id=\"milmor/gpt-mini\", \n",
    "                filename=f\"{ckpt_dir}/checkpoint\",\n",
    "                local_dir='./')\n",
    "\n",
    "config_file = hf_hub_download(repo_id=\"milmor/mini-gpt\", \n",
    "                filename=\"openwt_512/openwt_512_config.json\",\n",
    "                local_dir='./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78c3c9cf-64d8-4f7f-9126-168b93c5c8f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(config_file) as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7900cc4-774a-46d2-8561-95471eac4092",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = keras_nlp.tokenizers.WordPieceTokenizer(\n",
    "    vocabulary=config['vocab_file'],\n",
    "    sequence_length=config['seq_len'] + 1,\n",
    "    lowercase=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c02fb3f3-d5a4-42b1-be8e-7cef0dda2701",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = GPT(vocab_size=config['vocab_size'], \n",
    "            maxlen=config['seq_len'], emb_dim=config['emb_dim'],\n",
    "            heads=config['heads'], mlp_dim=config['mlp_dim'],\n",
    "            depth=config['depth'], rate=config['dropout'], \n",
    "            initializer=config['initializer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfee4545-c05d-407d-aa82-8fbbbb6a2302",
   "metadata": {},
   "source": [
    "- Initialize the model with a tokenized input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e254b330-34c0-4f26-87ba-d38e0d9054ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = 'I love the wolf'\n",
    "t_context = tokenizer(tf_text.normalize_utf8(context, 'NFKD'))[tf.newaxis, :config['seq_len']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a77377e-e1b5-4615-8836-6c47f4aa4c27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 512, 30000), dtype=float32, numpy=\n",
       "array([[[ 0.04053944,  0.02580857, -0.02134609, ...,  0.06464612,\n",
       "          0.00159945, -0.18666302],\n",
       "        [ 0.05024419,  0.07753551,  0.01507949, ...,  0.1112728 ,\n",
       "          0.02672572, -0.17179757],\n",
       "        [-0.01681338,  0.03965631,  0.12883598, ..., -0.02745748,\n",
       "          0.05715263, -0.18807063],\n",
       "        ...,\n",
       "        [-0.04165641,  0.03784008,  0.086284  , ...,  0.07254027,\n",
       "          0.03297675, -0.1646466 ],\n",
       "        [-0.0728814 ,  0.00634096,  0.11156805, ...,  0.07823642,\n",
       "          0.0475099 , -0.14655234],\n",
       "        [-0.06854442, -0.00762512,  0.09210709, ...,  0.07022417,\n",
       "          0.03737502, -0.15992373]]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(t_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e05c83d8-e1f1-4c8c-b57e-bd280de7a2d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"gpt\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " token_embedding (TokenEmbed  multiple                 7811072   \n",
      " ding)                                                           \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         multiple                  0         \n",
      "                                                                 \n",
      " transformer_block (Transfor  multiple                 527104    \n",
      " merBlock)                                                       \n",
      "                                                                 \n",
      " transformer_block_1 (Transf  multiple                 527104    \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " transformer_block_2 (Transf  multiple                 527104    \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " transformer_block_3 (Transf  multiple                 527104    \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " transformer_block_4 (Transf  multiple                 527104    \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " transformer_block_5 (Transf  multiple                 527104    \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " transformer_block_6 (Transf  multiple                 527104    \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " transformer_block_7 (Transf  multiple                 527104    \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " transformer_block_8 (Transf  multiple                 527104    \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " transformer_block_9 (Transf  multiple                 527104    \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " transformer_block_10 (Trans  multiple                 527104    \n",
      " formerBlock)                                                    \n",
      "                                                                 \n",
      " transformer_block_11 (Trans  multiple                 527104    \n",
      " formerBlock)                                                    \n",
      "                                                                 \n",
      " layer_normalization_24 (Lay  multiple                 512       \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " dense_72 (Dense)            multiple                  7710000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,846,832\n",
      "Trainable params: 21,846,832\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0f2388-a41b-4d5e-8dc1-9e946d813b5e",
   "metadata": {},
   "source": [
    "- Restore weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8c435cd-bf54-46f7-be67-1c573a4558fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint restored from openwt_512/best-ckpt/ckpt-934000 at step 934000\n"
     ]
    }
   ],
   "source": [
    "ckpt = tf.train.Checkpoint(model=model, step=tf.Variable(0))\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, directory=ckpt_dir, \n",
    "                                          max_to_keep=1)\n",
    "ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "print(f'Checkpoint restored from {ckpt_manager.latest_checkpoint} at step {int(ckpt.step)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9b801c3-2a1f-4c72-a058-1e3335c4a0f4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I love the wolfy spot I hate a year , one month and you were sweatbing a cliff like some roxcy peel . ( FUTY MEKLITES ASSID AF EY . PLVENATT STOP : OLSLAS OLD ANNOILS : The Arre muckin ( borating its like that ’ a true - fun way with which she likes ! . So good ) There are plenty smile of like me like them all out here - there the IH . That may surprise for much that while this article in full and there for its most popular IM had on display since earlier to begin drawing as this version on my iPhone at IRXM / xY3Hm IS ) have , we ' had been doing everything together to share about and even blisss through IN in front of 2 , 800 students per a ( which does more to snubs me at these end people though that should end though in most things that will likely change ) because if no person got me through into these tpenie they had it ' d not matter I want to throw down every couple in every single place there and my first time with AF would actually do just little I was on my mind . So the same IH wanted a way better work together . Whenever my father got to that very spot it doesn do not get great all now to lose . One would just wonder it ? I just bought up my last iGad , just at least the time the muzzes started ( after many trips at last at most from first in time it only brought off too short until in a day so would be better - and for now will leave more cries that should go there without my stumor in it ’ S ? Awk , the only idea to move with my head has I now was an anodgy and you cannot keep doing an idea ? Well why all up now ( and there also would actually go right off for if she would find herself ) does go into your place again this summer — at home of these beautiful hoax ( also on iOS yet ? I also want AB ? If the time makes more people go off on it ’ em now you see ) And with that this article is like doing them and so if things keep a spades the only fun . ( My daughter can no more ? . p _ id to watch in other cases with it at 3 ? Or would your school might ask\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = sample(model, context, config['seq_len'], config['vocab_file'], k=40)\n",
    "text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
